{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import logging as log\n",
    "log.basicConfig(level=log.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from baselines.utils import *\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "os.environ['WANDB_ENTITY'] = 'contract-nli-db'\n",
    "os.environ['WANDB_PROJECT'] = 'contract-nli'\n",
    "os.environ['WANDB_LOG_MODEL'] = 'end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_data_dir': '../dataset/',\n",
       " 'train_path': 'train.json',\n",
       " 'test_path': 'test.json',\n",
       " 'dev_path': 'dev.json',\n",
       " 'model_name': 'bert-base-uncased',\n",
       " 'max_length': 512,\n",
       " 'models_save_dir': './scratch/shu7bh/contract_nli/models',\n",
       " 'dataset_dir': './scratch/shu7bh/contract_nli/dataset',\n",
       " 'results_dir': './scratch/shu7bh/contract_nli/results',\n",
       " 'trained_model_dir': '/scratch/shu7bh/contract_nli/trained_model/',\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['model_name'] = 'bert-base-uncased'\n",
    "cfg['trained_model_dir'] = '/scratch/shu7bh/contract_nli/trained_model/'\n",
    "cfg['batch_size'] = 32\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dir if not exists\n",
    "from pathlib import Path\n",
    "Path(cfg[\"models_save_dir\"]).mkdir(parents=True, exist_ok=True)\n",
    "Path(cfg[\"dataset_dir\"]).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): huggingface.co:443\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 139631601342096 on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/a661b1a138dac6dc5590367402d100765010ffd6.lock\n",
      "DEBUG:filelock:Lock 139631601342096 acquired on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/a661b1a138dac6dc5590367402d100765010ffd6.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /bert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 28\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcddc667754e4d199f4f1ac53222b81b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 139631601342096 on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/a661b1a138dac6dc5590367402d100765010ffd6.lock\n",
      "DEBUG:filelock:Lock 139631601342096 released on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/a661b1a138dac6dc5590367402d100765010ffd6.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 139631544206608 on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/45a2321a7ecfdaaf60a6c1fd7f5463994cc8907d.lock\n",
      "DEBUG:filelock:Lock 139631544206608 acquired on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/45a2321a7ecfdaaf60a6c1fd7f5463994cc8907d.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 570\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c9560fc5ae4a74b96c070e22ba2164",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 139631544206608 on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/45a2321a7ecfdaaf60a6c1fd7f5463994cc8907d.lock\n",
      "DEBUG:filelock:Lock 139631544206608 released on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/45a2321a7ecfdaaf60a6c1fd7f5463994cc8907d.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 139631338435408 on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/fb140275c155a9c7c5a3b3e0e77a9e839594a938.lock\n",
      "DEBUG:filelock:Lock 139631338435408 acquired on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/fb140275c155a9c7c5a3b3e0e77a9e839594a938.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /bert-base-uncased/resolve/main/vocab.txt HTTP/1.1\" 200 231508\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "48c5df9697c94c81a29c772fa7f02ae2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 139631338435408 on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/fb140275c155a9c7c5a3b3e0e77a9e839594a938.lock\n",
      "DEBUG:filelock:Lock 139631338435408 released on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/fb140275c155a9c7c5a3b3e0e77a9e839594a938.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer.json HTTP/1.1\" 200 0\n",
      "DEBUG:filelock:Attempting to acquire lock 139631338227280 on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/949a6f013d67eb8a5b4b5b46026217b888021b88.lock\n",
      "DEBUG:filelock:Lock 139631338227280 acquired on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/949a6f013d67eb8a5b4b5b46026217b888021b88.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"GET /bert-base-uncased/resolve/main/tokenizer.json HTTP/1.1\" 200 466062\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c1fc29af0b984fcf81667a05b999b180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:filelock:Attempting to release lock 139631338227280 on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/949a6f013d67eb8a5b4b5b46026217b888021b88.lock\n",
      "DEBUG:filelock:Lock 139631338227280 released on /home2/shu7bh/.cache/huggingface/hub/models--bert-base-uncased/blobs/949a6f013d67eb8a5b4b5b46026217b888021b88.lock\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/added_tokens.json HTTP/1.1\" 404 0\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/special_tokens_map.json HTTP/1.1\" 404 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('./scratch/shu7bh/contract_nli/models/tokenizer_config.json',\n",
       " './scratch/shu7bh/contract_nli/models/special_tokens_map.json',\n",
       " './scratch/shu7bh/contract_nli/models/vocab.txt',\n",
       " './scratch/shu7bh/contract_nli/models/added_tokens.json',\n",
       " './scratch/shu7bh/contract_nli/models/tokenizer.json')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg['model_name'])\n",
    "\n",
    "tokenizer.save_pretrained(cfg['models_save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg['models_save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypothesis_idx(hypothesis_name):\n",
    "    return int(hypothesis_name.split('-')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch\n",
    "\n",
    "class NLIDataset(Dataset):\n",
    "    def __init__(self, documents, tokenizer, hypothesis, context_sizes, surround_character_size):\n",
    "        label_dict = get_labels()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.tokenizer.add_special_tokens({'additional_special_tokens': ['[SPAN]']})\n",
    "\n",
    "        data_points = []\n",
    "        contexts = [{}]\n",
    "\n",
    "        for context_size in context_sizes:\n",
    "            for i, doc in enumerate(documents):\n",
    "                char_idx = 0\n",
    "                while char_idx < len(doc['text']):\n",
    "                    ic(char_idx)\n",
    "                    document_spans = doc['spans']\n",
    "                    cur_context = {\n",
    "                        'doc_id': i,\n",
    "                        'start_char_idx': char_idx,\n",
    "                        'end_char_idx': char_idx + context_size,\n",
    "                        'spans' : [],\n",
    "                    }\n",
    "\n",
    "                    for j, (start, end) in enumerate(document_spans):\n",
    "                        if end <= char_idx:\n",
    "                            continue\n",
    "\n",
    "                        cur_context['spans'].append({\n",
    "                            'start_char_idx': max(start, char_idx),\n",
    "                            'end_char_idx': min(end, char_idx + context_size),\n",
    "                            'marked': start >= char_idx and end <= char_idx + context_size,\n",
    "                            'span_id': j\n",
    "                        })\n",
    "\n",
    "                        if end > char_idx + context_size:\n",
    "                            break\n",
    "\n",
    "                    if cur_context == contexts[-1]:\n",
    "                        char_idx = cur_context['end_char_idx'] - surround_character_size\n",
    "                        continue\n",
    "\n",
    "                    contexts.append(cur_context)\n",
    "                    if len(cur_context['spans']) == 1 and not cur_context['spans'][0]['marked']:\n",
    "                        char_idx = cur_context['end_char_idx'] - surround_character_size\n",
    "                    else:\n",
    "                        char_idx = cur_context['spans'][-1]['start_char_idx'] - surround_character_size\n",
    "\n",
    "        contexts.pop(0)\n",
    "\n",
    "        for nda_name, nda_desc in hypothesis.items():\n",
    "            for i, context in enumerate(contexts):\n",
    "\n",
    "                nli_label = label_dict[documents[context['doc_id']]['annotation_sets'][0]['annotations'][nda_name]['choice']]\n",
    "\n",
    "                data_point = {}\n",
    "                data_point['hypotheis'] = nda_desc\n",
    "                cur_premise = \"\"\n",
    "                data_point['marked_beg'] = context['spans'][0]['marked']\n",
    "                data_point['marked_end'] = context['spans'][-1]['marked']\n",
    "                doc_id = context['doc_id']\n",
    "                hypothesis_id = get_hypothesis_idx(nda_name)\n",
    "                span_ids = []\n",
    "\n",
    "                if len(context['spans']) == 1:\n",
    "                    data_point['marked_end'] = True\n",
    "\n",
    "                span_labels = []\n",
    "\n",
    "                for span in context['spans']:\n",
    "                    val = int(span['span_id'] in documents[context['doc_id']]['annotation_sets'][0]['annotations'][nda_name]['spans'])\n",
    "\n",
    "                    val = 2 * val - 1 # making 0 -> -1 and 1 -> 1\n",
    "\n",
    "                    if span['marked']:\n",
    "                        span_labels.append(val)\n",
    "                        span_ids.append(span['span_id'])\n",
    "\n",
    "                    cur_premise += ' [SPAN] '\n",
    "                    cur_premise += documents[context['doc_id']]['text'][span['start_char_idx']:span['end_char_idx']]\n",
    "\n",
    "                data_point['premise'] = cur_premise\n",
    "                \n",
    "                if nli_label == get_labels()['NotMentioned']:\n",
    "                    span_labels = torch.zeros(len(span_labels), dtype=torch.long)\n",
    "\n",
    "                data_point['nli_label'] = torch.tensor(nli_label, dtype=torch.long)\n",
    "                data_point['span_labels'] = torch.tensor(span_labels, dtype=torch.long)\n",
    "                data_point['doc_id'] = torch.tensor(doc_id, dtype=torch.long)\n",
    "                data_point['hypothesis_id'] = torch.tensor(hypothesis_id, dtype=torch.long)\n",
    "                data_point['span_ids'] = torch.tensor(span_ids, dtype=torch.long)\n",
    "\n",
    "                data_points.append(data_point)\n",
    "\n",
    "        self.data_points = data_points\n",
    "        self.span_token_id = self.tokenizer.convert_tokens_to_ids('[SPAN]')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_points)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokenized_data = self.tokenizer(\n",
    "            [self.data_points[idx]['hypotheis']],\n",
    "            [self.data_points[idx]['premise']],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        tokenized_data['input_ids'] = tokenized_data['input_ids'].squeeze()\n",
    "        tokenized_data['attention_mask'] = tokenized_data['attention_mask'].squeeze()\n",
    "        tokenized_data['token_type_ids'] = tokenized_data['token_type_ids'].squeeze()\n",
    "\n",
    "        span_indices = torch.where(tokenized_data['input_ids'] == self.span_token_id)[0]\n",
    "\n",
    "        if not self.data_points[idx]['marked_beg']:\n",
    "            span_indices = span_indices[1:]\n",
    "        \n",
    "        if not self.data_points[idx]['marked_end'] or tokenized_data['attention_mask'][-1] == 0:\n",
    "            span_indices = span_indices[:-1]\n",
    "        \n",
    "        span_ids = self.data_points[idx]['span_ids']\n",
    "        span_ids = span_ids[:len(span_indices)]\n",
    "\n",
    "        return {\n",
    "            'input_ids': tokenized_data['input_ids'],\n",
    "            'attention_mask': tokenized_data['attention_mask'],\n",
    "            'token_type_ids': tokenized_data['token_type_ids'],\n",
    "            'span_indices': span_indices,\n",
    "            'nli_label': self.data_points[idx]['nli_label'],\n",
    "            'span_labels': self.data_points[idx]['span_labels'][:len(span_indices)],\n",
    "            'data_for_metrics': {\n",
    "                'doc_id': self.data_points[idx]['doc_id'],\n",
    "                'hypothesis_id': self.data_points[idx]['hypothesis_id'],\n",
    "                'span_ids': span_ids,\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_18292/1745476268.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data_point['span_labels'] = torch.tensor(span_labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "train_data = load_data(os.path.join(cfg['raw_data_dir'], cfg['train_path']))\n",
    "dev_data = load_data(os.path.join(cfg['raw_data_dir'], cfg['dev_path']))\n",
    "test_data = load_data(os.path.join(cfg['raw_data_dir'], cfg['test_path']))\n",
    "\n",
    "hypothesis = get_hypothesis(train_data)\n",
    "\n",
    "train_data = train_data['documents']\n",
    "dev_data = dev_data['documents']\n",
    "test_data = test_data['documents']\n",
    "\n",
    "train_data = train_data[:2]\n",
    "dev_data = dev_data[:2]\n",
    "test_data = test_data[:2]\n",
    "\n",
    "ic.disable()\n",
    "\n",
    "ic(len(train_data), len(dev_data), len(test_data))\n",
    "train_dataset = NLIDataset(train_data, tokenizer, hypothesis, [1000, 1100, 1200], 50)\n",
    "dev_dataset = NLIDataset(dev_data, tokenizer, hypothesis, [1000, 1100, 1200], 50)\n",
    "test_dataset = NLIDataset(test_data, tokenizer, hypothesis, [1000, 1100, 1200], 50)\n",
    "\n",
    "ic.enable()\n",
    "\n",
    "del train_data\n",
    "del dev_data\n",
    "del test_data\n",
    "del hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(train_dataset): 1394\n",
      "    len(dev_dataset): 2448\n",
      "    len(test_dataset): 1887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1394, 2448, 1887)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(len(train_dataset), len(dev_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def count_classes(dataset):\n",
    "#     zero_ct = 0\n",
    "#     one_ct = 0\n",
    "#     minus_one_ct = 0\n",
    "    \n",
    "#     for x in dataset:\n",
    "#         for i in x['span_labels']:\n",
    "#             if i == 0:\n",
    "#                 zero_ct += 1\n",
    "#             elif i == 1:\n",
    "#                 one_ct += 1\n",
    "#             else:\n",
    "#                 minus_one_ct += 1\n",
    "                \n",
    "#     return zero_ct, one_ct, minus_one_ct\n",
    "\n",
    "# zero_cnt_train, one_cnt_train, minus_one_cnt_train = count_classes(train_dataset)\n",
    "# ic(count_classes(dev_dataset))\n",
    "# ic(count_classes(test_dataset))\n",
    "\n",
    "\n",
    "\n",
    "    # for x in train_dataset:\n",
    "    #     if x['nli_label'] == 1 or x['nli_label'] == 2:\n",
    "    #         for i in x['span_labels']:\n",
    "    #             if i == 0:\n",
    "    #                 zero_ct += 1\n",
    "    #             else:\n",
    "    #                 one_ct += 1\n",
    "\n",
    "    # ic(zero_ct, one_ct)\n",
    "\n",
    "    # zero_ct = 0\n",
    "    # one_ct = 0\n",
    "\n",
    "    # for x in dev_dataset:\n",
    "    #     if x['nli_label'] == 1 or x['nli_label'] == 2:\n",
    "    #         for i in x['span_labels']:\n",
    "    #             if i == 0:\n",
    "    #                 zero_ct += 1\n",
    "    #             else:\n",
    "    #                 one_ct += 1\n",
    "\n",
    "    # ic(zero_ct, one_ct)\n",
    "\n",
    "    # zero_ct = 0\n",
    "    # one_ct = 0\n",
    "\n",
    "    # for x in test_dataset:\n",
    "    #     if x['nli_label'] == 1 or x['nli_label'] == 2:\n",
    "    #         for i in x['span_labels']:\n",
    "    #             if i == 0:\n",
    "    #                 zero_ct += 1\n",
    "    #             else:\n",
    "    #                 one_ct += 1\n",
    "\n",
    "    # ic(zero_ct, one_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "def get_class_weights(dataset):\n",
    "    nli_labels = [x['nli_label'] for x in dataset]\n",
    "\n",
    "    span_labels = []\n",
    "    for x in dataset:\n",
    "        span_labels.extend(x['span_labels'].tolist())\n",
    "\n",
    "    nli_weights = compute_class_weight('balanced', classes=np.unique(nli_labels), y=np.array(nli_labels))\n",
    "\n",
    "    nli_weights = nli_weights.tolist()\n",
    "\n",
    "    span_labels = [x for x in span_labels if x != -1]\n",
    "    span_labels = np.array(span_labels)\n",
    "    span_weight = np.sum(span_labels == 0) / np.sum(span_labels)\n",
    "\n",
    "    return nli_weights, span_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_weights, span_weight = get_class_weights(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| nli_weights: [0.8734335839598998, 0.7061803444782169, 2.2777777777777777]\n",
      "    span_weight: 36.73118279569893\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0.8734335839598998, 0.7061803444782169, 2.2777777777777777],\n",
       " 36.73118279569893)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(nli_weights, span_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# span_labels = []\n",
    "\n",
    "# for x in train_dataset:\n",
    "#     span_labels.extend(x['span_labels'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# span_weights = compute_class_weight('balanced', classes=np.unique(span_labels), y=np.array(span_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_data_dir': '../dataset/',\n",
       " 'train_path': 'train.json',\n",
       " 'test_path': 'test.json',\n",
       " 'dev_path': 'dev.json',\n",
       " 'model_name': 'bert-base-uncased',\n",
       " 'max_length': 512,\n",
       " 'models_save_dir': './scratch/shu7bh/contract_nli/models',\n",
       " 'dataset_dir': './scratch/shu7bh/contract_nli/dataset',\n",
       " 'results_dir': './scratch/shu7bh/contract_nli/results',\n",
       " 'trained_model_dir': '/scratch/shu7bh/contract_nli/trained_model/',\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:torch.distributed.nn.jit.instantiator:Created a temporary directory at /tmp/tmpjzbnwsig\n",
      "INFO:torch.distributed.nn.jit.instantiator:Writing /tmp/tmpjzbnwsig/_remote_module_non_scriptable.py\n"
     ]
    }
   ],
   "source": [
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "\n",
    "class ContractNLIConfig(PretrainedConfig):\n",
    "    # def __init__(self, lambda_ = 1, bert_model_name = cfg['model_name'], num_labels = len(get_labels()), ignore_span_label = 2, nli_weights = nli_weights, span_weight = span_weight, **kwargs):\n",
    "    def __init__(self, nli_weights = [1, 1, 1], span_weight = 1, lambda_ = 1, bert_model_name = cfg['model_name'], num_labels = len(get_labels()), ignore_span_label = 2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.bert_model_name = bert_model_name\n",
    "        self.num_labels = num_labels\n",
    "        self.lambda_ = lambda_\n",
    "        self.ignore_span_label = ignore_span_label\n",
    "        self.nli_weights = nli_weights\n",
    "        self.span_weight = span_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "from torch import nn\n",
    "\n",
    "class ContractNLI(PreTrainedModel):\n",
    "    config_class = ContractNLIConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert = AutoModel.from_pretrained(config.bert_model_name)\n",
    "        self.bert.resize_token_embeddings(self.bert.config.vocab_size + 1, pad_to_multiple_of=8)\n",
    "        self.bert.eval()\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.embedding_dim = self.bert.config.hidden_size\n",
    "        self.num_labels = config.num_labels\n",
    "        self.lambda_ = config.lambda_\n",
    "        self.nli_criterion = nn.CrossEntropyLoss(weight=torch.tensor(self.config.nli_weights, dtype=torch.float32))\n",
    "        self.span_criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.config.span_weight, dtype=torch.float32))\n",
    "\n",
    "        self.span_classifier = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim * 4, self.embedding_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.embedding_dim * 4, self.embedding_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.embedding_dim * 2, 1)\n",
    "        )\n",
    "\n",
    "        self.nli_classifier = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim * 4, self.embedding_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.embedding_dim * 4, self.embedding_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.embedding_dim * 2, self.num_labels)\n",
    "        )\n",
    "\n",
    "        # initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            # use the same initialization as bert\n",
    "            module.weight.data.normal_(mean=0.0, std=self.bert.config.initializer_range)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, span_indices):\n",
    "        outputs = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True).hidden_states[-4:]\n",
    "        outputs = torch.stack(outputs, dim=0)\n",
    "        outputs = outputs.permute([1, 2, 0, 3])\n",
    "        outputs = outputs.reshape([outputs.shape[0], outputs.shape[1], -1])\n",
    "\n",
    "        gather = torch.gather(outputs, 1, span_indices.unsqueeze(2).expand(-1, -1, outputs.shape[-1]))\n",
    "\n",
    "        masked_gather = gather[span_indices != 0]\n",
    "        span_logits = self.span_classifier(masked_gather)\n",
    "        nli_logits = self.nli_classifier(outputs[:, 0, :])\n",
    "\n",
    "        return span_logits, nli_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "class ContractNLITrainer(Trainer):\n",
    "    def __init__(self, *args, data_collator=None, **kwargs):\n",
    "        super().__init__(*args, data_collator=data_collator, **kwargs)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        span_label = inputs.pop('span_labels')\n",
    "        nli_label = inputs.pop('nli_label')\n",
    "        inputs.pop('data_for_metrics')\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        span_logits, nli_logits = outputs[0], outputs[1]\n",
    "        \n",
    "        # span labels = -1, means ignore \n",
    "        \n",
    "        mask = span_label != -1\n",
    "        span_label = span_label[mask]\n",
    "        span_logits = span_logits[mask]\n",
    "        \n",
    "        span_label = span_label.float()\n",
    "        span_logits = span_logits.float()\n",
    "        \n",
    "        span_label = span_label.view(-1)\n",
    "        span_logits = span_logits.view(-1)        \n",
    "\n",
    "        # if len(true_span_labels) == 0 or len(pred_span_labels) != len(true_span_labels):\n",
    "        #     span_loss = torch.tensor(0, dtype=torch.float32, device=DEVICE)\n",
    "        # else:\n",
    "        #     span_loss = self.model.span_criterion(pred_span_labels, true_span_labels)\n",
    "        \n",
    "        if len(span_label) == 0:\n",
    "            span_loss = torch.tensor(0, dtype=torch.float32, device=DEVICE)\n",
    "        else:\n",
    "            span_loss = self.model.span_criterion(span_logits, span_label)\n",
    "\n",
    "        nli_loss = self.model.nli_criterion(nli_logits, nli_label)\n",
    "\n",
    "        if torch.isnan(nli_loss):\n",
    "            nli_loss = torch.tensor(0, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "        if torch.isnan(span_loss):\n",
    "            span_loss = torch.tensor(0, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "        loss = span_loss + self.model.lambda_ * nli_loss\n",
    "\n",
    "        if loss.item() == 0:\n",
    "            loss = torch.tensor(0, dtype=torch.float32, device=DEVICE, requires_grad=True)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(features):\n",
    "        span_indices_list = [feature['span_indices'] for feature in features]\n",
    "        max_len = max([len(span_indices) for span_indices in span_indices_list])\n",
    "        span_indices_list = [torch.cat([span_indices, torch.zeros(max_len - len(span_indices), dtype=torch.long)]) for span_indices in span_indices_list]\n",
    "\n",
    "        span_ids_list = [feature['data_for_metrics']['span_ids'] for feature in features]\n",
    "        max_len = max([len(span_ids) for span_ids in span_ids_list])\n",
    "        \n",
    "        # pad to get the doc id and hypothesis id for each input while evaluating\n",
    "        span_ids_list = [torch.cat([span_ids, torch.full((max_len - len(span_ids),), -1)]) for span_ids in span_ids_list]\n",
    "        \n",
    "        input_ids = torch.stack([feature['input_ids'] for feature in features])\n",
    "        attention_mask = torch.stack([feature['attention_mask'] for feature in features])\n",
    "        token_type_ids = torch.stack([feature['token_type_ids'] for feature in features])\n",
    "        span_indices = torch.stack(span_indices_list)\n",
    "        nli_label = torch.stack([feature['nli_label'] for feature in features])\n",
    "        span_label = torch.cat([feature['span_labels'] for feature in features], dim=0)\n",
    "        data_for_metrics = {\n",
    "            'doc_id': torch.stack([feature['data_for_metrics']['doc_id'] for feature in features]),\n",
    "            'hypothesis_id': torch.stack([feature['data_for_metrics']['hypothesis_id'] for feature in features]),\n",
    "            'span_ids': torch.stack(span_ids_list),\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'span_indices': span_indices,\n",
    "            'nli_label': nli_label,\n",
    "            'span_labels': span_label,\n",
    "            'data_for_metrics': data_for_metrics,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    auto_find_batch_size=True,\n",
    "    output_dir=cfg['results_dir'],   # output directory\n",
    "    num_train_epochs=20,            # total number of training epochs\n",
    "    gradient_accumulation_steps=4,   # number of updates steps to accumulate before performing a backward/update pass\n",
    "    logging_strategy='steps',\n",
    "    eval_steps=2,\n",
    "    save_steps=2,\n",
    "    logging_steps=2,\n",
    "    evaluation_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    label_names=['nli_label', 'span_labels', 'data_for_metrics'],\n",
    "    report_to='none',\n",
    "    # report_to='wandb',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_hp_space(trial):\n",
    "    return {\n",
    "        \"method\": \"random\",\n",
    "        \"metric\": {\n",
    "            \"name\": \"eval/loss\",\n",
    "            \"goal\": \"minimize\"\n",
    "        },\n",
    "        \"parameters\": {\n",
    "            \"learning_rate\": {\n",
    "                \"values\": [1e-5, 3e-5, 5e-5]\n",
    "            },\n",
    "            \"lambda_\": {\n",
    "                \"values\": [0.05, 0.1, 0.4]\n",
    "            },\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(trial):\n",
    "    if trial is None:\n",
    "        return ContractNLI(ContractNLIConfig(nli_weights=nli_weights, span_weight=span_weight))\n",
    "\n",
    "    return ContractNLI(ContractNLIConfig(nli_weights=nli_weights, span_weight=span_weight, lambda_=trial['lambda_']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "# config = ContractNLIConfig()\n",
    "\n",
    "# model = ContractNLI(config).to(DEVICE)\n",
    "trainer = ContractNLITrainer(\n",
    "    model=None,                          # the instantiated 🤗 Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=dev_dataset,            # evaluation dataset\n",
    "    data_collator=ContractNLITrainer.collate_fn,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.001)],\n",
    "    model_init=model_init,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='860' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  3/860 00:00 < 04:59, 2.86 it/s, Epoch 0.05/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2.239600</td>\n",
       "      <td>12.790403</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home2/shu7bh/Courses/ANLP/Project/Contract-NLI/source_code/contract_nli_bert_train.ipynb Cell 28\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bgnode070/home2/shu7bh/Courses/ANLP/Project/Contract-NLI/source_code/contract_nli_bert_train.ipynb#X36sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m trainer\u001b[39m.\u001b[39;49mtrain()\n",
      "File \u001b[0;32m~/miniforge3/envs/nli/lib/python3.11/site-packages/transformers/trainer.py:1556\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1554\u001b[0m         hf_hub_utils\u001b[39m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1555\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1556\u001b[0m     \u001b[39mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1557\u001b[0m         args\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m   1558\u001b[0m         resume_from_checkpoint\u001b[39m=\u001b[39;49mresume_from_checkpoint,\n\u001b[1;32m   1559\u001b[0m         trial\u001b[39m=\u001b[39;49mtrial,\n\u001b[1;32m   1560\u001b[0m         ignore_keys_for_eval\u001b[39m=\u001b[39;49mignore_keys_for_eval,\n\u001b[1;32m   1561\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge3/envs/nli/lib/python3.11/site-packages/accelerate/utils/memory.py:136\u001b[0m, in \u001b[0;36mfind_executable_batch_size.<locals>.decorator\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mNo executable batch size found, reached zero.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    135\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 136\u001b[0m     \u001b[39mreturn\u001b[39;00m function(batch_size, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    137\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    138\u001b[0m     \u001b[39mif\u001b[39;00m should_reduce_batch_size(e):\n",
      "File \u001b[0;32m~/miniforge3/envs/nli/lib/python3.11/site-packages/transformers/trainer.py:1930\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1927\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mepoch \u001b[39m=\u001b[39m epoch \u001b[39m+\u001b[39m (step \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m \u001b[39m+\u001b[39m steps_skipped) \u001b[39m/\u001b[39m steps_in_epoch\n\u001b[1;32m   1928\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_step_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n\u001b[0;32m-> 1930\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_maybe_log_save_evaluate(tr_loss, model, trial, epoch, ignore_keys_for_eval)\n\u001b[1;32m   1931\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1932\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_substep_end(args, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/miniforge3/envs/nli/lib/python3.11/site-packages/transformers/trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2265\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlr_scheduler\u001b[39m.\u001b[39mstep(metrics[metric_to_check])\n\u001b[1;32m   2267\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol\u001b[39m.\u001b[39mshould_save:\n\u001b[0;32m-> 2268\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save_checkpoint(model, trial, metrics\u001b[39m=\u001b[39;49mmetrics)\n\u001b[1;32m   2269\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcallback_handler\u001b[39m.\u001b[39mon_save(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcontrol)\n",
      "File \u001b[0;32m~/miniforge3/envs/nli/lib/python3.11/site-packages/transformers/trainer.py:2325\u001b[0m, in \u001b[0;36mTrainer._save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   2323\u001b[0m run_dir \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_output_dir(trial\u001b[39m=\u001b[39mtrial)\n\u001b[1;32m   2324\u001b[0m output_dir \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(run_dir, checkpoint_folder)\n\u001b[0;32m-> 2325\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msave_model(output_dir, _internal_call\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   2326\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_deepspeed_enabled:\n\u001b[1;32m   2327\u001b[0m     \u001b[39m# under zero3 model file itself doesn't get saved since it's bogus! Unless deepspeed\u001b[39;00m\n\u001b[1;32m   2328\u001b[0m     \u001b[39m# config `stage3_gather_16bit_weights_on_model_save` is True\u001b[39;00m\n\u001b[1;32m   2329\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped\u001b[39m.\u001b[39msave_checkpoint(output_dir)\n",
      "File \u001b[0;32m~/miniforge3/envs/nli/lib/python3.11/site-packages/transformers/trainer.py:2817\u001b[0m, in \u001b[0;36mTrainer.save_model\u001b[0;34m(self, output_dir, _internal_call)\u001b[0m\n\u001b[1;32m   2814\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel_wrapped\u001b[39m.\u001b[39msave_checkpoint(output_dir)\n\u001b[1;32m   2816\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mshould_save:\n\u001b[0;32m-> 2817\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_save(output_dir)\n\u001b[1;32m   2819\u001b[0m \u001b[39m# Push to the Hub when `save_model` is called by the user.\u001b[39;00m\n\u001b[1;32m   2820\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39margs\u001b[39m.\u001b[39mpush_to_hub \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m _internal_call:\n",
      "File \u001b[0;32m~/miniforge3/envs/nli/lib/python3.11/site-packages/transformers/trainer.py:2875\u001b[0m, in \u001b[0;36mTrainer._save\u001b[0;34m(self, output_dir, state_dict)\u001b[0m\n\u001b[1;32m   2873\u001b[0m             torch\u001b[39m.\u001b[39msave(state_dict, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(output_dir, WEIGHTS_NAME))\n\u001b[1;32m   2874\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 2875\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49msave_pretrained(\n\u001b[1;32m   2876\u001b[0m         output_dir, state_dict\u001b[39m=\u001b[39;49mstate_dict, safe_serialization\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49margs\u001b[39m.\u001b[39;49msave_safetensors\n\u001b[1;32m   2877\u001b[0m     )\n\u001b[1;32m   2879\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   2880\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtokenizer\u001b[39m.\u001b[39msave_pretrained(output_dir)\n",
      "File \u001b[0;32m~/miniforge3/envs/nli/lib/python3.11/site-packages/transformers/modeling_utils.py:1993\u001b[0m, in \u001b[0;36mPreTrainedModel.save_pretrained\u001b[0;34m(self, save_directory, is_main_process, state_dict, save_function, push_to_hub, max_shard_size, safe_serialization, variant, token, save_peft_format, **kwargs)\u001b[0m\n\u001b[1;32m   1991\u001b[0m         safe_save_file(shard, os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_directory, shard_file), metadata\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mformat\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39mpt\u001b[39m\u001b[39m\"\u001b[39m})\n\u001b[1;32m   1992\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1993\u001b[0m         save_function(shard, os\u001b[39m.\u001b[39;49mpath\u001b[39m.\u001b[39;49mjoin(save_directory, shard_file))\n\u001b[1;32m   1995\u001b[0m \u001b[39mif\u001b[39;00m index \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1996\u001b[0m     path_to_weights \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(save_directory, _add_variant(WEIGHTS_NAME, variant))\n",
      "File \u001b[0;32m~/miniforge3/envs/nli/lib/python3.11/site-packages/torch/serialization.py:440\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    437\u001b[0m _check_save_filelike(f)\n\u001b[1;32m    439\u001b[0m \u001b[39mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 440\u001b[0m     \u001b[39mwith\u001b[39;49;00m _open_zipfile_writer(f) \u001b[39mas\u001b[39;49;00m opened_zipfile:\n\u001b[1;32m    441\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    442\u001b[0m         \u001b[39mreturn\u001b[39;49;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nli/lib/python3.11/site-packages/torch/serialization.py:291\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    290\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__exit__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfile_like\u001b[39m.\u001b[39;49mwrite_end_of_file()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.hyperparameter_search(\n",
    "#     hp_space=wandb_hp_space,\n",
    "#     backend='wandb',\n",
    "#     n_trials=5,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ContractNLI.from_pretrained(cfg['trained_model_dir']).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# trainer = ContractNLITrainer(\n",
    "#     model=model,                  # the instantiated 🤗 Transformers model to be trained\n",
    "#     args=training_args,                  # training arguments, defined above\n",
    "#     train_dataset=train_dataset,         # training dataset\n",
    "#     eval_dataset=dev_dataset,            # evaluation dataset\n",
    "#     data_collator=ContractNLITrainer.collate_fn,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
