{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForMaskedLM\n",
    "import logging as log\n",
    "log.basicConfig(level=log.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')\n",
    "from baselines.utils import *\n",
    "import os\n",
    "\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = '1'\n",
    "\n",
    "os.environ['WANDB_ENTITY'] = 'contract-nli-db'\n",
    "os.environ['WANDB_PROJECT'] = 'contract-nli'\n",
    "os.environ['WANDB_LOG_MODEL'] = 'end'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_data_dir': '../dataset/',\n",
       " 'train_path': 'train.json',\n",
       " 'test_path': 'test.json',\n",
       " 'dev_path': 'dev.json',\n",
       " 'model_name': 'bert-base-uncased',\n",
       " 'max_length': 512,\n",
       " 'models_save_dir': '/scratch/shu7bh/contract_nli/models',\n",
       " 'dataset_dir': '/scratch/shu7bh/contract_nli/dataset',\n",
       " 'results_dir': '/scratch/shu7bh/contract_nli/results',\n",
       " 'trained_model_dir': '/scratch/shu7bh/contract_nli/trained_model/',\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg['model_name'] = 'bert-base-uncased'\n",
    "cfg['trained_model_dir'] = '/scratch/shu7bh/contract_nli/trained_model/'\n",
    "cfg['batch_size'] = 32\n",
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dir if not exists\n",
    "from pathlib import Path\n",
    "Path(cfg[\"models_save_dir\"]).mkdir(parents=True, exist_ok=True)\n",
    "Path(cfg[\"dataset_dir\"]).mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:Resetting dropped connection: huggingface.co\n",
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/tokenizer_config.json HTTP/1.1\" 200 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('/scratch/shu7bh/contract_nli/models/tokenizer_config.json',\n",
       " '/scratch/shu7bh/contract_nli/models/special_tokens_map.json',\n",
       " '/scratch/shu7bh/contract_nli/models/vocab.txt',\n",
       " '/scratch/shu7bh/contract_nli/models/added_tokens.json',\n",
       " '/scratch/shu7bh/contract_nli/models/tokenizer.json')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg['model_name'])\n",
    "\n",
    "tokenizer.save_pretrained(cfg['models_save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(cfg['models_save_dir'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from icecream import ic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypothesis_idx(hypothesis_name):\n",
    "    return int(hypothesis_name.split('-')[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import random\n",
    "import torch\n",
    "\n",
    "class NLIDataset(Dataset):\n",
    "    def __init__(self, documents, tokenizer, hypothesis, context_sizes, surround_character_size):\n",
    "        label_dict = get_labels()\n",
    "        self.tokenizer = tokenizer\n",
    "\n",
    "        self.tokenizer.add_special_tokens({'additional_special_tokens': ['[SPAN]']})\n",
    "\n",
    "        data_points = []\n",
    "        contexts = [{}]\n",
    "\n",
    "        for context_size in context_sizes:\n",
    "            for i, doc in enumerate(documents):\n",
    "                char_idx = 0\n",
    "                while char_idx < len(doc['text']):\n",
    "                    ic(char_idx)\n",
    "                    document_spans = doc['spans']\n",
    "                    cur_context = {\n",
    "                        'doc_id': i,\n",
    "                        'start_char_idx': char_idx,\n",
    "                        'end_char_idx': char_idx + context_size,\n",
    "                        'spans' : [],\n",
    "                    }\n",
    "\n",
    "                    for j, (start, end) in enumerate(document_spans):\n",
    "                        if end <= char_idx:\n",
    "                            continue\n",
    "\n",
    "                        cur_context['spans'].append({\n",
    "                            'start_char_idx': max(start, char_idx),\n",
    "                            'end_char_idx': min(end, char_idx + context_size),\n",
    "                            'marked': start >= char_idx and end <= char_idx + context_size,\n",
    "                            'span_id': j\n",
    "                        })\n",
    "\n",
    "                        if end > char_idx + context_size:\n",
    "                            break\n",
    "\n",
    "                    if cur_context == contexts[-1]:\n",
    "                        char_idx = cur_context['end_char_idx'] - surround_character_size\n",
    "                        continue\n",
    "\n",
    "                    contexts.append(cur_context)\n",
    "                    if len(cur_context['spans']) == 1 and not cur_context['spans'][0]['marked']:\n",
    "                        char_idx = cur_context['end_char_idx'] - surround_character_size\n",
    "                    else:\n",
    "                        char_idx = cur_context['spans'][-1]['start_char_idx'] - surround_character_size\n",
    "\n",
    "        contexts.pop(0)\n",
    "\n",
    "        for nda_name, nda_desc in hypothesis.items():\n",
    "            for i, context in enumerate(contexts):\n",
    "\n",
    "                nli_label = label_dict[documents[context['doc_id']]['annotation_sets'][0]['annotations'][nda_name]['choice']]\n",
    "\n",
    "                data_point = {}\n",
    "                data_point['hypotheis'] = nda_desc\n",
    "                cur_premise = \"\"\n",
    "                data_point['marked_beg'] = context['spans'][0]['marked']\n",
    "                data_point['marked_end'] = context['spans'][-1]['marked']\n",
    "                doc_id = context['doc_id']\n",
    "                hypothesis_id = get_hypothesis_idx(nda_name)\n",
    "                span_ids = []\n",
    "\n",
    "                if len(context['spans']) == 1:\n",
    "                    data_point['marked_end'] = True\n",
    "\n",
    "                span_labels = []\n",
    "\n",
    "                for span in context['spans']:\n",
    "                    val = int(span['span_id'] in documents[context['doc_id']]['annotation_sets'][0]['annotations'][nda_name]['spans'])\n",
    "\n",
    "                    val = 2 * val - 1 # making 0 -> -1 and 1 -> 1\n",
    "\n",
    "                    if span['marked']:\n",
    "                        span_labels.append(val)\n",
    "                        span_ids.append(span['span_id'])\n",
    "\n",
    "                    cur_premise += ' [SPAN] '\n",
    "                    cur_premise += documents[context['doc_id']]['text'][span['start_char_idx']:span['end_char_idx']]\n",
    "\n",
    "                data_point['premise'] = cur_premise\n",
    "                \n",
    "                if nli_label == get_labels()['NotMentioned']:\n",
    "                    span_labels = torch.zeros(len(span_labels), dtype=torch.long)\n",
    "\n",
    "                data_point['nli_label'] = torch.tensor(nli_label, dtype=torch.long)\n",
    "                data_point['span_labels'] = torch.tensor(span_labels, dtype=torch.long)\n",
    "                data_point['doc_id'] = torch.tensor(doc_id, dtype=torch.long)\n",
    "                data_point['hypothesis_id'] = torch.tensor(hypothesis_id, dtype=torch.long)\n",
    "                data_point['span_ids'] = torch.tensor(span_ids, dtype=torch.long)\n",
    "\n",
    "                data_points.append(data_point)\n",
    "\n",
    "        self.data_points = data_points\n",
    "        self.span_token_id = self.tokenizer.convert_tokens_to_ids('[SPAN]')\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_points)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        tokenized_data = self.tokenizer(\n",
    "            [self.data_points[idx]['hypotheis']],\n",
    "            [self.data_points[idx]['premise']],\n",
    "            padding='max_length',\n",
    "            truncation=True,\n",
    "            return_tensors='pt',\n",
    "        )\n",
    "\n",
    "        tokenized_data['input_ids'] = tokenized_data['input_ids'].squeeze()\n",
    "        tokenized_data['attention_mask'] = tokenized_data['attention_mask'].squeeze()\n",
    "        tokenized_data['token_type_ids'] = tokenized_data['token_type_ids'].squeeze()\n",
    "\n",
    "        span_indices = torch.where(tokenized_data['input_ids'] == self.span_token_id)[0]\n",
    "\n",
    "        if not self.data_points[idx]['marked_beg']:\n",
    "            span_indices = span_indices[1:]\n",
    "        \n",
    "        if not self.data_points[idx]['marked_end'] or tokenized_data['attention_mask'][-1] == 0:\n",
    "            span_indices = span_indices[:-1]\n",
    "        \n",
    "        span_ids = self.data_points[idx]['span_ids']\n",
    "        span_ids = span_ids[:len(span_indices)]\n",
    "\n",
    "        return {\n",
    "            'input_ids': tokenized_data['input_ids'],\n",
    "            'attention_mask': tokenized_data['attention_mask'],\n",
    "            'token_type_ids': tokenized_data['token_type_ids'],\n",
    "            'span_indices': span_indices,\n",
    "            'nli_label': self.data_points[idx]['nli_label'],\n",
    "            'span_labels': self.data_points[idx]['span_labels'][:len(span_indices)],\n",
    "            'data_for_metrics': {\n",
    "                'doc_id': self.data_points[idx]['doc_id'],\n",
    "                'hypothesis_id': self.data_points[idx]['hypothesis_id'],\n",
    "                'span_ids': span_ids,\n",
    "            }\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_12680/1745476268.py:91: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  data_point['span_labels'] = torch.tensor(span_labels, dtype=torch.long)\n"
     ]
    }
   ],
   "source": [
    "train_data = load_data(os.path.join(cfg['raw_data_dir'], cfg['train_path']))\n",
    "dev_data = load_data(os.path.join(cfg['raw_data_dir'], cfg['dev_path']))\n",
    "test_data = load_data(os.path.join(cfg['raw_data_dir'], cfg['test_path']))\n",
    "\n",
    "hypothesis = get_hypothesis(train_data)\n",
    "\n",
    "train_data = train_data['documents']\n",
    "dev_data = dev_data['documents']\n",
    "test_data = test_data['documents']\n",
    "\n",
    "train_data = train_data[:100]\n",
    "dev_data = dev_data[:100]\n",
    "test_data = test_data[:100]\n",
    "\n",
    "ic.disable()\n",
    "\n",
    "ic(len(train_data), len(dev_data), len(test_data))\n",
    "train_dataset = NLIDataset(train_data, tokenizer, hypothesis, [1000, 1100, 1200], 50)\n",
    "dev_dataset = NLIDataset(dev_data, tokenizer, hypothesis, [1000, 1100, 1200], 50)\n",
    "test_dataset = NLIDataset(test_data, tokenizer, hypothesis, [1000, 1100, 1200], 50)\n",
    "\n",
    "ic.enable()\n",
    "\n",
    "del train_data\n",
    "del dev_data\n",
    "del test_data\n",
    "del hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(train_dataset): 1394\n",
      "    len(dev_dataset): 2448\n",
      "    len(test_dataset): 1887\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1394, 2448, 1887)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic(len(train_dataset), len(dev_dataset), len(test_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# def count_classes(dataset):\n",
    "#     zero_ct = 0\n",
    "#     one_ct = 0\n",
    "#     minus_one_ct = 0\n",
    "    \n",
    "#     for x in dataset:\n",
    "#         for i in x['span_labels']:\n",
    "#             if i == 0:\n",
    "#                 zero_ct += 1\n",
    "#             elif i == 1:\n",
    "#                 one_ct += 1\n",
    "#             else:\n",
    "#                 minus_one_ct += 1\n",
    "                \n",
    "#     return zero_ct, one_ct, minus_one_ct\n",
    "\n",
    "# zero_cnt_train, one_cnt_train, minus_one_cnt_train = count_classes(train_dataset)\n",
    "# ic(count_classes(dev_dataset))\n",
    "# ic(count_classes(test_dataset))\n",
    "\n",
    "\n",
    "\n",
    "    # for x in train_dataset:\n",
    "    #     if x['nli_label'] == 1 or x['nli_label'] == 2:\n",
    "    #         for i in x['span_labels']:\n",
    "    #             if i == 0:\n",
    "    #                 zero_ct += 1\n",
    "    #             else:\n",
    "    #                 one_ct += 1\n",
    "\n",
    "    # ic(zero_ct, one_ct)\n",
    "\n",
    "    # zero_ct = 0\n",
    "    # one_ct = 0\n",
    "\n",
    "    # for x in dev_dataset:\n",
    "    #     if x['nli_label'] == 1 or x['nli_label'] == 2:\n",
    "    #         for i in x['span_labels']:\n",
    "    #             if i == 0:\n",
    "    #                 zero_ct += 1\n",
    "    #             else:\n",
    "    #                 one_ct += 1\n",
    "\n",
    "    # ic(zero_ct, one_ct)\n",
    "\n",
    "    # zero_ct = 0\n",
    "    # one_ct = 0\n",
    "\n",
    "    # for x in test_dataset:\n",
    "    #     if x['nli_label'] == 1 or x['nli_label'] == 2:\n",
    "    #         for i in x['span_labels']:\n",
    "    #             if i == 0:\n",
    "    #                 zero_ct += 1\n",
    "    #             else:\n",
    "    #                 one_ct += 1\n",
    "\n",
    "    # ic(zero_ct, one_ct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import numpy as np\n",
    "\n",
    "def get_class_weights(dataset):\n",
    "    nli_labels = [x['nli_label'] for x in dataset]\n",
    "\n",
    "    span_labels = []\n",
    "    for x in dataset:\n",
    "        span_labels.extend(x['span_labels'].tolist())\n",
    "\n",
    "    nli_weights = compute_class_weight('balanced', classes=np.unique(nli_labels), y=np.array(nli_labels))\n",
    "\n",
    "    nli_weights = nli_weights.tolist()\n",
    "\n",
    "    span_labels = [x for x in span_labels if x != -1]\n",
    "    span_labels = np.array(span_labels)\n",
    "    span_weight = np.sum(span_labels == 0) / np.sum(span_labels)\n",
    "\n",
    "    return nli_weights, span_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "nli_weights, span_weight = get_class_weights(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.8734335839598998, 0.7061803444782169, 2.2777777777777777],\n",
       " 36.73118279569893)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nli_weights, span_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# span_labels = []\n",
    "\n",
    "# for x in train_dataset:\n",
    "#     span_labels.extend(x['span_labels'].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# span_weights = compute_class_weight('balanced', classes=np.unique(span_labels), y=np.array(span_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw_data_dir': '../dataset/',\n",
       " 'train_path': 'train.json',\n",
       " 'test_path': 'test.json',\n",
       " 'dev_path': 'dev.json',\n",
       " 'model_name': 'bert-base-uncased',\n",
       " 'max_length': 512,\n",
       " 'models_save_dir': '/scratch/shu7bh/contract_nli/models',\n",
       " 'dataset_dir': '/scratch/shu7bh/contract_nli/dataset',\n",
       " 'results_dir': '/scratch/shu7bh/contract_nli/results',\n",
       " 'trained_model_dir': '/scratch/shu7bh/contract_nli/trained_model/',\n",
       " 'batch_size': 32}"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import PreTrainedModel, PretrainedConfig\n",
    "\n",
    "class ContractNLIConfig(PretrainedConfig):\n",
    "    # def __init__(self, lambda_ = 1, bert_model_name = cfg['model_name'], num_labels = len(get_labels()), ignore_span_label = 2, nli_weights = nli_weights, span_weight = span_weight, **kwargs):\n",
    "    def __init__(self, nli_weights = [1, 1, 1], span_weight = 1, lambda_ = 1, bert_model_name = cfg['model_name'], num_labels = len(get_labels()), ignore_span_label = 2, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.bert_model_name = bert_model_name\n",
    "        self.num_labels = num_labels\n",
    "        self.lambda_ = lambda_\n",
    "        self.ignore_span_label = ignore_span_label\n",
    "        self.nli_weights = nli_weights\n",
    "        self.span_weight = span_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "from torch import nn\n",
    "\n",
    "class ContractNLI(PreTrainedModel):\n",
    "    config_class = ContractNLIConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.bert = AutoModel.from_pretrained(config.bert_model_name)\n",
    "        self.bert.resize_token_embeddings(self.bert.config.vocab_size + 1, pad_to_multiple_of=8)\n",
    "        self.bert.eval()\n",
    "        for param in self.bert.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.embedding_dim = self.bert.config.hidden_size\n",
    "        self.num_labels = config.num_labels\n",
    "        self.lambda_ = config.lambda_\n",
    "        self.nli_criterion = nn.CrossEntropyLoss(weight=torch.tensor(self.config.nli_weights, dtype=torch.float32))\n",
    "        self.span_criterion = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(self.config.span_weight, dtype=torch.float32))\n",
    "\n",
    "        self.span_classifier = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, self.embedding_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.embedding_dim * 4, self.embedding_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.embedding_dim * 2, 1)\n",
    "        )\n",
    "\n",
    "        self.nli_classifier = nn.Sequential(\n",
    "            nn.Linear(self.embedding_dim, self.embedding_dim * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.embedding_dim * 4, self.embedding_dim * 2),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(self.embedding_dim * 2, self.num_labels)\n",
    "        )\n",
    "\n",
    "        # initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def _init_weights(self, module):\n",
    "        \"\"\" Initialize the weights \"\"\"\n",
    "        if isinstance(module, (nn.Linear, nn.Embedding)):\n",
    "            # use the same initialization as bert\n",
    "            module.weight.data.normal_(mean=0.0, std=self.bert.config.initializer_range)\n",
    "        elif isinstance(module, nn.LayerNorm):\n",
    "            module.bias.data.zero_()\n",
    "            module.weight.data.fill_(1.0)\n",
    "        if isinstance(module, nn.Linear) and module.bias is not None:\n",
    "            module.bias.data.zero_()\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, token_type_ids, span_indices):\n",
    "        outputs = self.bert(input_ids, attention_mask, token_type_ids, output_hidden_states=True).hidden_states[-1]\n",
    "\n",
    "        gather = torch.gather(outputs, 1, span_indices.unsqueeze(2).expand(-1, -1, outputs.shape[-1]))\n",
    "\n",
    "        masked_gather = gather[span_indices != 0]\n",
    "        span_logits = self.span_classifier(masked_gather)\n",
    "        nli_logits = self.nli_classifier(outputs[:, 0, :])\n",
    "\n",
    "        return span_logits, nli_logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "class ContractNLITrainer(Trainer):\n",
    "    def __init__(self, *args, data_collator=None, **kwargs):\n",
    "        super().__init__(*args, data_collator=data_collator, **kwargs)\n",
    "\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        span_label = inputs.pop('span_labels')\n",
    "        nli_label = inputs.pop('nli_label')\n",
    "        inputs.pop('data_for_metrics')\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        span_logits, nli_logits = outputs[0], outputs[1]\n",
    "        \n",
    "        # span labels = -1, means ignore \n",
    "        \n",
    "        mask = span_label != -1\n",
    "        span_label = span_label[mask]\n",
    "        span_logits = span_logits[mask]\n",
    "        \n",
    "        span_label = span_label.float()\n",
    "        span_logits = span_logits.float()\n",
    "        \n",
    "        span_label = span_label.view(-1)\n",
    "        span_logits = span_logits.view(-1)        \n",
    "\n",
    "        # if len(true_span_labels) == 0 or len(pred_span_labels) != len(true_span_labels):\n",
    "        #     span_loss = torch.tensor(0, dtype=torch.float32, device=DEVICE)\n",
    "        # else:\n",
    "        #     span_loss = self.model.span_criterion(pred_span_labels, true_span_labels)\n",
    "        \n",
    "        if len(span_label) == 0:\n",
    "            span_loss = torch.tensor(0, dtype=torch.float32, device=DEVICE)\n",
    "        else:\n",
    "            span_loss = self.model.span_criterion(span_logits, span_label)\n",
    "\n",
    "        nli_loss = self.model.nli_criterion(nli_logits, nli_label)\n",
    "\n",
    "        if torch.isnan(nli_loss):\n",
    "            nli_loss = torch.tensor(0, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "        if torch.isnan(span_loss):\n",
    "            span_loss = torch.tensor(0, dtype=torch.float32, device=DEVICE)\n",
    "\n",
    "        loss = span_loss + self.model.lambda_ * nli_loss\n",
    "\n",
    "        if loss.item() == 0:\n",
    "            loss = torch.tensor(0, dtype=torch.float32, device=DEVICE, requires_grad=True)\n",
    "\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    "\n",
    "    @staticmethod\n",
    "    def collate_fn(features):\n",
    "        span_indices_list = [feature['span_indices'] for feature in features]\n",
    "        max_len = max([len(span_indices) for span_indices in span_indices_list])\n",
    "        span_indices_list = [torch.cat([span_indices, torch.zeros(max_len - len(span_indices), dtype=torch.long)]) for span_indices in span_indices_list]\n",
    "\n",
    "        span_ids_list = [feature['data_for_metrics']['span_ids'] for feature in features]\n",
    "        max_len = max([len(span_ids) for span_ids in span_ids_list])\n",
    "        \n",
    "        # pad to get the doc id and hypothesis id for each input while evaluating\n",
    "        span_ids_list = [torch.cat([span_ids, torch.full((max_len - len(span_ids),), -1)]) for span_ids in span_ids_list]\n",
    "        \n",
    "        input_ids = torch.stack([feature['input_ids'] for feature in features])\n",
    "        attention_mask = torch.stack([feature['attention_mask'] for feature in features])\n",
    "        token_type_ids = torch.stack([feature['token_type_ids'] for feature in features])\n",
    "        span_indices = torch.stack(span_indices_list)\n",
    "        nli_label = torch.stack([feature['nli_label'] for feature in features])\n",
    "        span_label = torch.cat([feature['span_labels'] for feature in features], dim=0)\n",
    "        data_for_metrics = {\n",
    "            'doc_id': torch.stack([feature['data_for_metrics']['doc_id'] for feature in features]),\n",
    "            'hypothesis_id': torch.stack([feature['data_for_metrics']['hypothesis_id'] for feature in features]),\n",
    "            'span_ids': torch.stack(span_ids_list),\n",
    "        }\n",
    "\n",
    "        return {\n",
    "            'input_ids': input_ids,\n",
    "            'attention_mask': attention_mask,\n",
    "            'token_type_ids': token_type_ids,\n",
    "            'span_indices': span_indices,\n",
    "            'nli_label': nli_label,\n",
    "            'span_labels': span_label,\n",
    "            'data_for_metrics': data_for_metrics,\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    auto_find_batch_size=True,\n",
    "    output_dir=cfg['results_dir'],   # output directory\n",
    "    num_train_epochs=20,            # total number of training epochs\n",
    "    gradient_accumulation_steps=4,   # number of updates steps to accumulate before performing a backward/update pass\n",
    "    logging_strategy='steps',\n",
    "    eval_steps=1000,\n",
    "    save_steps=1000,\n",
    "    logging_steps=1000,\n",
    "    evaluation_strategy='steps',\n",
    "    save_strategy='steps',\n",
    "    save_total_limit=2,\n",
    "    load_best_model_at_end=True,\n",
    "    fp16=True,\n",
    "    label_names=['nli_label', 'span_labels', 'data_for_metrics'],\n",
    "    report_to='none',\n",
    "    # report_to='wandb',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import EarlyStoppingCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wandb_hp_space(trial):\n",
    "    return {\n",
    "        \"method\": \"random\",\n",
    "        \"metric\": {\n",
    "            \"name\": \"eval/loss\",\n",
    "            \"goal\": \"minimize\"\n",
    "        },\n",
    "        \"parameters\": {\n",
    "            \"learning_rate\": {\n",
    "                \"values\": [1e-5, 3e-5, 5e-5]\n",
    "            },\n",
    "            \"lambda_\": {\n",
    "                \"values\": [0.05, 0.1, 0.4]\n",
    "            },\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init(trial):\n",
    "    if trial is None:\n",
    "        return ContractNLI(ContractNLIConfig(nli_weights=nli_weights, span_weight=span_weight))\n",
    "\n",
    "    return ContractNLI(ContractNLIConfig(nli_weights=nli_weights, span_weight=span_weight, lambda_=trial['lambda_']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:urllib3.connectionpool:https://huggingface.co:443 \"HEAD /bert-base-uncased/resolve/main/config.json HTTP/1.1\" 200 0\n"
     ]
    }
   ],
   "source": [
    "# config = ContractNLIConfig()\n",
    "\n",
    "# model = ContractNLI(config).to(DEVICE)\n",
    "trainer = ContractNLITrainer(\n",
    "    model=None,                          # the instantiated ðŸ¤— Transformers model to be trained\n",
    "    args=training_args,                  # training arguments, defined above\n",
    "    train_dataset=train_dataset,         # training dataset\n",
    "    eval_dataset=dev_dataset,            # evaluation dataset\n",
    "    data_collator=ContractNLITrainer.collate_fn,\n",
    "    callbacks=[EarlyStoppingCallback(early_stopping_patience=3, early_stopping_threshold=0.001)],\n",
    "    model_init=model_init,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.hyperparameter_search(\n",
    "#     hp_space=wandb_hp_space,\n",
    "#     backend='wandb',\n",
    "#     n_trials=5,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ContractNLI.from_pretrained(cfg['trained_model_dir']).to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('disk I/O error')).History will not be written to the database.\n"
     ]
    }
   ],
   "source": [
    "# trainer = ContractNLITrainer(\n",
    "#     model=model,                  # the instantiated ðŸ¤— Transformers model to be trained\n",
    "#     args=training_args,                  # training arguments, defined above\n",
    "#     train_dataset=train_dataset,         # training dataset\n",
    "#     eval_dataset=dev_dataset,            # evaluation dataset\n",
    "#     data_collator=ContractNLITrainer.collate_fn,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
