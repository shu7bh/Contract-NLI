{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import json\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = {\n",
    "    'DIR': '../dataset/',\n",
    "    'train_path': 'train.json',\n",
    "    'test_path': 'test.json',\n",
    "    'dev_path': 'dev.json',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "def load_data(path: str) -> json:\n",
    "    with open(os.path.join(cfg['DIR'], path), 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_str(str: str) -> str:\n",
    "    # remove '\\n' character\n",
    "    str = str.replace('\\n', ' ')\n",
    "    # remove '\\t' character\n",
    "    str = re.sub(r'\\\\t', ' ', str)\n",
    "    # remove '\\r' character\n",
    "    str = re.sub(r'\\\\r', ' ', str)\n",
    "    # remove more than 2 consecutive occcurance of a character\n",
    "    str = re.sub(r'(.)\\1{2,}', r'\\1', str)\n",
    "    return str.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_data(data: dict) -> None:\n",
    "    for i in range(len(data['documents'])):\n",
    "        data['documents'][i]['text'] = clean_str(data['documents'][i]['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.metrics.pairwise import cosine_similarity\n",
    "# from tqdm import tqdm\n",
    "# def get_Ypred_Ytrue(data: dict, tfidf: TfidfVectorizer, hypothesis: dict, labels: dict, threshold : float = 0.1) -> (list, list):\n",
    "    \n",
    "#     X = []\n",
    "#     Y = []\n",
    "\n",
    "#     Y_pred = []\n",
    "#     Y_true = []\n",
    "\n",
    "#     hypothesis_vecs = {}\n",
    "#     for key, val in hypothesis.items():\n",
    "#         hypothesis_vecs[key] = tfidf.transform([val])\n",
    "\n",
    "#     for i in tqdm(range(len(data[\"documents\"]))):\n",
    "#         doc_text = data[\"documents\"][i][\"text\"]\n",
    "#         tokenized_doc = nltk.word_tokenize(doc_text)\n",
    "\n",
    "#         for i, span in enumerate(data[\"documents\"][i][\"spans\"]):\n",
    "#             start_idx = span[0]\n",
    "#             end_idx = span[1]\n",
    "\n",
    "#             # get the span text\n",
    "#             span_text = tokenized_doc[start_idx:end_idx]\n",
    "#             span_text = \" \".join(span_text)\n",
    "\n",
    "#             # get the span vector\n",
    "#             span_vector = tfidf.transform([span_text])\n",
    "\n",
    "#             for key, val in hypothesis.items():\n",
    "#                 cosine_sim = cosine_similarity(span_vector, hypothesis_vecs[key])[0][0]\n",
    "#                 # print(cosine_sim)\n",
    "                \n",
    "#                 if cosine_sim >= threshold:\n",
    "#                     Y_pred.append(1)\n",
    "#                 else: \n",
    "#                     Y_pred.append(0)\n",
    "\n",
    "#                 if i in data[\"documents\"][i][\"annotation_sets\"][0][\"annotations\"][key][\"spans\"]:\n",
    "#                     Y_true.append(1)\n",
    "#                 else:\n",
    "#                     Y_true.append(0)\n",
    "                \n",
    "#     return Y_pred, Y_true\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from tqdm import tqdm\n",
    "def get_Ypred_Ytrue(data: dict, tfidf: TfidfVectorizer, hypothesis: dict, labels: dict, threshold : float = 0.1) -> (list, list):\n",
    "\n",
    "    Y_pred = []\n",
    "    Y_true = []\n",
    "\n",
    "    hypothesis_vecs = {}\n",
    "    for key, val in hypothesis.items():\n",
    "        hypothesis_vecs[key] = tfidf.transform([val])\n",
    "\n",
    "    for i in tqdm(range(len(data[\"documents\"]))):\n",
    "        doc_text = data[\"documents\"][i][\"text\"]\n",
    "        tokenized_doc = nltk.word_tokenize(doc_text)\n",
    "\n",
    "        Y_pred_curdoc = []\n",
    "        Y_true_curdoc = []\n",
    "\n",
    "        for i, span in enumerate(data[\"documents\"][i][\"spans\"]):\n",
    "            start_idx = span[0]\n",
    "            end_idx = span[1]\n",
    "\n",
    "            # get the span text\n",
    "            span_text = tokenized_doc[start_idx:end_idx]\n",
    "            span_text = \" \".join(span_text)\n",
    "\n",
    "            # get the span vector\n",
    "            span_vector = tfidf.transform([span_text])\n",
    "\n",
    "            for key, val in hypothesis.items():\n",
    "                \n",
    "                \n",
    "                spans_for_key = data[\"documents\"][i][\"annotation_sets\"][0][\"annotations\"][key][\"spans\"]\n",
    "                \n",
    "                if(len(spans_for_key) == 0):\n",
    "                    continue\n",
    "\n",
    "                \n",
    "                cosine_sim = cosine_similarity(span_vector, hypothesis_vecs[key])[0][0]\n",
    "                Y_pred_curdoc.append(cosine_sim)\n",
    "                \n",
    "                if i in spans_for_key:\n",
    "                    Y_true_curdoc.append(1)\n",
    "                else:\n",
    "                    Y_true_curdoc.append(0)\n",
    "\n",
    "        Y_pred.append(Y_pred_curdoc)\n",
    "        Y_true.append(Y_true_curdoc)\n",
    "        \n",
    "    return Y_pred, Y_true\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hypothesis(data: dict) -> list:\n",
    "    hypothesis = {}\n",
    "    for key, value in data['labels'].items():\n",
    "        hypothesis[key] = clean_str(value['hypothesis'])\n",
    "    return hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "def get_labels() -> dict:\n",
    "    return {\n",
    "        'NotMentioned': 0,\n",
    "        'Entailment': 1,\n",
    "        'Contradiction': 2,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = load_data(cfg['train_path'])\n",
    "clean_data(train)\n",
    "hypothesis = get_hypothesis(train)\n",
    "labels = get_labels()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>TfidfVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">TfidfVectorizer</label><div class=\"sk-toggleable__content\"><pre>TfidfVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "TfidfVectorizer()"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_text = []\n",
    "\n",
    "for i in range(len(train[\"documents\"])):\n",
    "    all_text.append(train[\"documents\"][i][\"text\"])\n",
    "\n",
    "tfidf = TfidfVectorizer()\n",
    "tfidf.fit(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_curve\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def precision_at_80_recall(ypred, ytrue):\n",
    "    precision, recall, thresholds = precision_recall_curve(ytrue, ypred)\n",
    "    idx = (abs(recall - 0.8)).argmin()\n",
    "    return precision[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sklearn.metrics\n",
    "def precision_at_recall(y_true, y_prob, recall: float):\n",
    "    assert 0. <= recall <= 1.0\n",
    "    if len(y_true) == 0 or np.sum(y_true) == 0:\n",
    "        return np.nan\n",
    "    threshs = np.sort(np.unique(y_prob))[::-1]\n",
    "    # (len(np.unique(y_prob)), len(y_prob)) where first axis show prediction at different thresh\n",
    "    y_preds = y_prob[None, :] >= threshs[:, None]\n",
    "    recalls = np.logical_and(y_true[None, :], y_preds).sum(axis=1) / np.sum(y_true)\n",
    "    # check that recalls are monotonically increasing\n",
    "    assert np.all(recalls == np.sort(recalls))\n",
    "    # because of >= relationship, there exist at least one thresh that gives\n",
    "    # recall score of 1.0\n",
    "    thresh = threshs[np.where(recalls >= recall)[0][0]]\n",
    "    y_pred = y_prob >= thresh\n",
    "    return sklearn.metrics.precision_score(y_true, y_pred, zero_division=0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import wandb\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import classification_report\n",
    "\n",
    "# thresholds = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]\n",
    "# for threshold in thresholds:\n",
    "#     wandb.init(entity=\"contract-nli-db\", project=\"span_tf-if_cosine\")\n",
    "#     config = wandb.config\n",
    "\n",
    "#     config.threshold = threshold\n",
    "\n",
    "#     Y_pred, Y_true = get_Ypred_Ytrue(train, tfidf, hypothesis, labels, threshold=threshold)\n",
    "#     print(accuracy_score(Y_true, Y_pred))\n",
    "#     print(precision_at_80_recall(Y_pred, Y_true))\n",
    "#     wandb.log({\"precision_at_80_recall\": precision_at_80_recall(Y_pred, Y_true)})\n",
    "#     wandb.log({\"accuracy\": accuracy_score(Y_true, Y_pred)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/423 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 423/423 [04:15<00:00,  1.66it/s]\n"
     ]
    }
   ],
   "source": [
    "Y_pred, Y_true = get_Ypred_Ytrue(train, tfidf, hypothesis, labels, threshold=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_y_pred = np.concatenate(Y_pred)\n",
    "all_y_true = np.concatenate(Y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340686\n",
      "340686\n"
     ]
    }
   ],
   "source": [
    "print(len(all_y_pred))\n",
    "print(len(all_y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "print(precision_at_recall(np.array(all_y_true[:150000]), np.array(all_y_pred[:150000]), 0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Micro-Averaged Precision at 80% Recall: 0.0343796711509716\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Replace these arrays with your actual data\n",
    "true_labels = Y_true[0]\n",
    "predicted_probabilities = Y_pred[0]  # Predicted probabilities for Class 1\n",
    "\n",
    "# Sort instances by predicted probabilities in descending order\n",
    "sorted_indices = np.argsort(predicted_probabilities)[::-1]\n",
    "sorted_labels = [true_labels[i] for i in sorted_indices]\n",
    "\n",
    "# Initialize variables\n",
    "TP = 0\n",
    "FP = 0\n",
    "threshold_for_80_recall = None\n",
    "\n",
    "# Iterate through instances to find the threshold for 80% recall\n",
    "for i in range(len(sorted_labels)):\n",
    "    if sorted_labels[i] == 1:\n",
    "        TP += 1\n",
    "    else:\n",
    "        FP += 1\n",
    "    current_recall = TP / sum(sorted_labels)\n",
    "    if current_recall >= 0.8 and threshold_for_80_recall is None:\n",
    "        threshold_for_80_recall = predicted_probabilities[sorted_indices[i]]\n",
    "\n",
    "# Calculate precision at the threshold for 80% recall\n",
    "predicted_labels_at_threshold = [1 if prob >= threshold_for_80_recall else 0 for prob in predicted_probabilities]\n",
    "micro_averaged_precision_at_80_recall = precision_score(true_labels, predicted_labels_at_threshold, average='micro')\n",
    "\n",
    "print(\"Micro-Averaged Precision at 80% Recall:\", micro_averaged_precision_at_80_recall)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean average precision score:  0.023480328243149644\n"
     ]
    }
   ],
   "source": [
    "# calculate mean averaged precision\n",
    "from sklearn.metrics import average_precision_score\n",
    "average_prec_scores = []\n",
    "for i in range(len(Y_true)):\n",
    "    average_prec_scores.append(average_precision_score(Y_true[i], Y_pred[i]))\n",
    "print(\"Mean average precision score: \", np.mean(average_prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "prec_scores = []\n",
    "for i in range(len(Y_pred)):\n",
    "    prec_scores.append(precision_at_80_recall(Y_pred[i], Y_true[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.031757935216165545\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012605042016806723\n"
     ]
    }
   ],
   "source": [
    "print(prec_scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# micro average the precision over labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "550125\n",
      "9090\n"
     ]
    }
   ],
   "source": [
    "# print number of 0s in ytrue\n",
    "cnt = 0\n",
    "total = 0\n",
    "for i in range(len(Y_true)):\n",
    "    for j in range(len(Y_true[i])):\n",
    "        if Y_true[i][j] == 0:\n",
    "            cnt += 1\n",
    "        total += 1\n",
    "\n",
    "print(cnt)\n",
    "# print(total)\n",
    "print(total - cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03247863247863248\n"
     ]
    }
   ],
   "source": [
    "print(max(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01915006559231427\n"
     ]
    }
   ],
   "source": [
    "print(sum(prec_scores)/len(prec_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "423\n",
      "423\n"
     ]
    }
   ],
   "source": [
    "print(len(Y_pred))\n",
    "print(len(Y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# # check at what indices y_pred is true\n",
    "\n",
    "# indices = np.where(np.array(Y_pred) == 1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/ayush/ANLP/Project/Contract-NLI/baselines/span_tf-idf_cosine.ipynb Cell 19\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ayush/ANLP/Project/Contract-NLI/baselines/span_tf-idf_cosine.ipynb#X23sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mprint\u001b[39m(precision_at_80_recall(Y_pred, Y_true))\n",
      "\u001b[1;32m/home/ayush/ANLP/Project/Contract-NLI/baselines/span_tf-idf_cosine.ipynb Cell 19\u001b[0m line \u001b[0;36m5\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayush/ANLP/Project/Contract-NLI/baselines/span_tf-idf_cosine.ipynb#X23sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mprecision_at_80_recall\u001b[39m(ypred, ytrue):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/ayush/ANLP/Project/Contract-NLI/baselines/span_tf-idf_cosine.ipynb#X23sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     precision, recall, thresholds \u001b[39m=\u001b[39m precision_recall_curve(ytrue, ypred)\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayush/ANLP/Project/Contract-NLI/baselines/span_tf-idf_cosine.ipynb#X23sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     idx \u001b[39m=\u001b[39m (\u001b[39mabs\u001b[39m(recall \u001b[39m-\u001b[39m \u001b[39m0.8\u001b[39m))\u001b[39m.\u001b[39margmin()\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/ayush/ANLP/Project/Contract-NLI/baselines/span_tf-idf_cosine.ipynb#X23sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m precision[idx]\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/nli/lib/python3.11/site-packages/sklearn/utils/_param_validation.py:211\u001b[0m, in \u001b[0;36mvalidate_params.<locals>.decorator.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    205\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    206\u001b[0m     \u001b[39mwith\u001b[39;00m config_context(\n\u001b[1;32m    207\u001b[0m         skip_parameter_validation\u001b[39m=\u001b[39m(\n\u001b[1;32m    208\u001b[0m             prefer_skip_nested_validation \u001b[39mor\u001b[39;00m global_skip_validation\n\u001b[1;32m    209\u001b[0m         )\n\u001b[1;32m    210\u001b[0m     ):\n\u001b[0;32m--> 211\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    212\u001b[0m \u001b[39mexcept\u001b[39;00m InvalidParameterError \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    213\u001b[0m     \u001b[39m# When the function is just a wrapper around an estimator, we allow\u001b[39;00m\n\u001b[1;32m    214\u001b[0m     \u001b[39m# the function to delegate validation to the estimator, but we replace\u001b[39;00m\n\u001b[1;32m    215\u001b[0m     \u001b[39m# the name of the estimator by the name of the function in the error\u001b[39;00m\n\u001b[1;32m    216\u001b[0m     \u001b[39m# message to avoid confusion.\u001b[39;00m\n\u001b[1;32m    217\u001b[0m     msg \u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\n\u001b[1;32m    218\u001b[0m         \u001b[39mr\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m\\\u001b[39m\u001b[39mw+ must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    219\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mparameter of \u001b[39m\u001b[39m{\u001b[39;00mfunc\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m must be\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    220\u001b[0m         \u001b[39mstr\u001b[39m(e),\n\u001b[1;32m    221\u001b[0m     )\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/nli/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:952\u001b[0m, in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, probas_pred, pos_label, sample_weight, drop_intermediate)\u001b[0m\n\u001b[1;32m    852\u001b[0m \u001b[39m@validate_params\u001b[39m(\n\u001b[1;32m    853\u001b[0m     {\n\u001b[1;32m    854\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39my_true\u001b[39m\u001b[39m\"\u001b[39m: [\u001b[39m\"\u001b[39m\u001b[39marray-like\u001b[39m\u001b[39m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    863\u001b[0m     y_true, probas_pred, \u001b[39m*\u001b[39m, pos_label\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, drop_intermediate\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    864\u001b[0m ):\n\u001b[1;32m    865\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"Compute precision-recall pairs for different probability thresholds.\u001b[39;00m\n\u001b[1;32m    866\u001b[0m \n\u001b[1;32m    867\u001b[0m \u001b[39m    Note: this implementation is restricted to the binary classification task.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    950\u001b[0m \u001b[39m    array([0.1 , 0.35, 0.4 , 0.8 ])\u001b[39;00m\n\u001b[1;32m    951\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 952\u001b[0m     fps, tps, thresholds \u001b[39m=\u001b[39m _binary_clf_curve(\n\u001b[1;32m    953\u001b[0m         y_true, probas_pred, pos_label\u001b[39m=\u001b[39;49mpos_label, sample_weight\u001b[39m=\u001b[39;49msample_weight\n\u001b[1;32m    954\u001b[0m     )\n\u001b[1;32m    956\u001b[0m     \u001b[39mif\u001b[39;00m drop_intermediate \u001b[39mand\u001b[39;00m \u001b[39mlen\u001b[39m(fps) \u001b[39m>\u001b[39m \u001b[39m2\u001b[39m:\n\u001b[1;32m    957\u001b[0m         \u001b[39m# Drop thresholds corresponding to points where true positives (tps)\u001b[39;00m\n\u001b[1;32m    958\u001b[0m         \u001b[39m# do not change from the previous or subsequent point. This will keep\u001b[39;00m\n\u001b[1;32m    959\u001b[0m         \u001b[39m# only the first and last point for each tps value. All points\u001b[39;00m\n\u001b[1;32m    960\u001b[0m         \u001b[39m# with the same tps value have the same recall and thus x coordinate.\u001b[39;00m\n\u001b[1;32m    961\u001b[0m         \u001b[39m# They appear as a vertical line on the plot.\u001b[39;00m\n\u001b[1;32m    962\u001b[0m         optimal_idxs \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mwhere(\n\u001b[1;32m    963\u001b[0m             np\u001b[39m.\u001b[39mconcatenate(\n\u001b[1;32m    964\u001b[0m                 [[\u001b[39mTrue\u001b[39;00m], np\u001b[39m.\u001b[39mlogical_or(np\u001b[39m.\u001b[39mdiff(tps[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]), np\u001b[39m.\u001b[39mdiff(tps[\u001b[39m1\u001b[39m:])), [\u001b[39mTrue\u001b[39;00m]]\n\u001b[1;32m    965\u001b[0m             )\n\u001b[1;32m    966\u001b[0m         )[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/nli/lib/python3.11/site-packages/sklearn/metrics/_ranking.py:802\u001b[0m, in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    768\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Calculate true and false positives per binary classification threshold.\u001b[39;00m\n\u001b[1;32m    769\u001b[0m \n\u001b[1;32m    770\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    799\u001b[0m \u001b[39m    Decreasing score values.\u001b[39;00m\n\u001b[1;32m    800\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    801\u001b[0m \u001b[39m# Check to make sure y_true is valid\u001b[39;00m\n\u001b[0;32m--> 802\u001b[0m y_type \u001b[39m=\u001b[39m type_of_target(y_true, input_name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39my_true\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[1;32m    803\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mbinary\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mor\u001b[39;00m (y_type \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mmulticlass\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mand\u001b[39;00m pos_label \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m)):\n\u001b[1;32m    804\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m format is not supported\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(y_type))\n",
      "File \u001b[0;32m~/miniforge-pypy3/envs/nli/lib/python3.11/site-packages/sklearn/utils/multiclass.py:347\u001b[0m, in \u001b[0;36mtype_of_target\u001b[0;34m(y, input_name)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    342\u001b[0m     \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    343\u001b[0m         \u001b[39mnot\u001b[39;00m \u001b[39mhasattr\u001b[39m(y[\u001b[39m0\u001b[39m], \u001b[39m\"\u001b[39m\u001b[39m__array__\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    344\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(y[\u001b[39m0\u001b[39m], Sequence)\n\u001b[1;32m    345\u001b[0m         \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(y[\u001b[39m0\u001b[39m], \u001b[39mstr\u001b[39m)\n\u001b[1;32m    346\u001b[0m     ):\n\u001b[0;32m--> 347\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    348\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mYou appear to be using a legacy multi-label data\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    349\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m representation. Sequence of sequences are no\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    350\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m longer supported; use a binary array or sparse\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    351\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m matrix instead - the MultiLabelBinarizer\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    352\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39m transformer can convert to this format.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    353\u001b[0m         )\n\u001b[1;32m    354\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n\u001b[1;32m    355\u001b[0m     \u001b[39mpass\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: You appear to be using a legacy multi-label data representation. Sequence of sequences are no longer supported; use a binary array or sparse matrix instead - the MultiLabelBinarizer transformer can convert to this format."
     ]
    }
   ],
   "source": [
    "print(precision_at_80_recall(Y_pred, Y_true))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.01003371 0.00833362 0.00833371 ... 0.         0.         1.        ]\n",
      "[1.         0.13170558 0.13170558 ... 0.         0.         0.        ]\n",
      "[0.         0.00095059 0.00109179 ... 0.58955275 0.59666227 0.61560326]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "precision, recall, thresholds = precision_recall_curve(Y_true, Y_pred)\n",
    "print(precision)\n",
    "print(recall)\n",
    "print(thresholds)\n",
    "plt.plot(recall, precision)\n",
    "plt.xlabel(\"recall\")\n",
    "plt.ylabel(\"precision\")\n",
    "plt.title(\"Precision-Recall Curve\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "main",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
